const express = require("express");
const path = require("path");
// const fetch = require("node-fetch"); // Node 18+ å¯ç”¨å…¨åŸŸ fetchï¼Œä¹Ÿå¯ç”¨ node-fetch
const { Pinecone, ServerlessSpec } = require("@pinecone-database/pinecone");
const { OpenAI } = require("openai");

const app = express();
app.use(express.json());
app.use(express.static(path.join(__dirname, "public"))); // æä¾›å‰ç«¯éœæ…‹æª”æ¡ˆ

// è®€å–ç’°å¢ƒè®Šæ•¸
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const PINECONE_API_KEY = process.env.PINECONE_API_KEY;
const PINECONE_ENV = process.env.PINECONE_ENV;
const PINECONE_INDEX_NAME = process.env.PINECONE_INDEX_NAME;

// åˆå§‹åŒ– Pinecone å®¢æˆ¶ç«¯
const pc = new Pinecone({
  apiKey: PINECONE_API_KEY,
  // controllerHostUrl: "https://controller.us-east-1-aws.pinecone.io" // ä¾ç…§ä½ çš„ env region æ”¹
});

// å–å¾— Pinecone Index å¯¦ä¾‹
const pineconeIndex = pc.Index(PINECONE_INDEX_NAME);

console.log("ðŸ” Pinecone index:", PINECONE_INDEX_NAME);
console.log("ðŸ” Pinecone env:", PINECONE_ENV);
console.log("ðŸ” Controller URL:", "https://controller.us-east-1.pinecone.io");

// åˆå§‹åŒ– OpenAI
const openai = new OpenAI({ apiKey: OPENAI_API_KEY });

// POST /gpt è·¯ç”±ï¼šæŽ¥æ”¶å‰ç«¯è¼¸å…¥æ–‡å­—ï¼ŒæŸ¥ Pineconeï¼Œå†é€çµ¦ GPT
app.post("/gpt", async (req, res) => {

  /* æ¸¬è©¦å‰ç«¯fetch("/gpt") æ˜¯å¦èƒ½æ­£å¸¸å‘¼å«å¾Œç«¯ï¼Œä»¥åŠå¾Œç«¯ route æ˜¯å¦èƒ½å›žå‚³ JSON
  console.log("æ¸¬è©¦æ”¶åˆ°è«‹æ±‚", req.body);
  res.json({ reply: "å¾Œç«¯æ¸¬è©¦æˆåŠŸï¼" });
  */

  const userText = req.body.text;
  console.log("æ”¶åˆ°ç·´ç¿’å…§å®¹ï¼š", userText);

  try {
  // -----------------------------
  // 1ï¸âƒ£ å…ˆå‘¼å« OpenAI Embeddings ç”Ÿæˆå‘é‡
  // -----------------------------
  const embeddingResponse = await openai.embeddings.create({
    model: "text-embedding-3-small",
    input: userText
  });

  // âœ… ç›´æŽ¥å–å›ž JS objectï¼Œä¸è¦å† .json()
  const userVector = embeddingResponse.data[0].embedding;

  // -----------------------------
  // 2ï¸âƒ£ æŸ¥è©¢ Pinecone
  // -----------------------------
  const queryResponse = await pineconeIndex.query({
    vector: userVector,
    topK: 3, // å–æœ€ç›¸ä¼¼çš„å‰ä¸‰å€‹æ®µè½
    includeMetadata: true
  });

  console.log("Pinecone æŸ¥è©¢çµæžœï¼š", JSON.stringify(queryResponse, null, 2));

  // å›žå‚³æŸ¥åˆ°çš„æ®µè½ (å…ˆæ¸¬è©¦ Pinecone)
  const matchedTexts = queryResponse.matches.map(m => m.metadata.text);
  res.json({
    reply: "Pinecone æŸ¥è©¢æ¸¬è©¦æˆåŠŸï¼\n\næ‰¾åˆ°çš„æ®µè½ï¼š\n" + matchedTexts.join("\n---\n")
  });

  } catch (err) {
    console.error("ç™¼ç”ŸéŒ¯èª¤ï¼š", err);
    res.status(500).json({ reply: "âŒ ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦\n\n" + err.message });
  }
});

  /* 
  try {
    // 1ï¸âƒ£ å…ˆç”¨ OpenAI çš„ embedding ç”Ÿæˆå‘é‡
    const embeddingResponse = await fetch("https://api.openai.com/v1/embeddings", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: "text-embedding-3-small",
        input: userText
      })
    });

    const embeddingData = await embeddingResponse.json();
    const userEmbedding = embeddingData.data[0].embedding; // å–å‡ºå‘é‡
    console.log("ä½¿ç”¨è€…å‘é‡ç”Ÿæˆå®Œæˆ");

    // 2ï¸âƒ£ æŸ¥è©¢ Pinecone æ‰¾æœ€ç›¸ä¼¼çš„æ•™æ
    const queryResponse = await pineconeIndex.query({
      vector: userEmbedding,
      topK: 3, // å–å¾—æœ€ç›¸ä¼¼çš„ 3 ç­†
      includeMetadata: true
    });

    // æŠŠæ‰¾åˆ°çš„æ®µè½å…§å®¹çµ„æˆ GPT prompt
    let contextText = "";
    queryResponse.matches.forEach((match, idx) => {
      contextText += `æ®µè½ ${idx + 1}: ${match.metadata.text}\n`;
    });

    console.log("å¾ž Pinecone å–å‡ºçš„ç›¸ä¼¼æ•™æï¼š", contextText);

    // 3ï¸âƒ£ æŠŠä½¿ç”¨è€…è¼¸å…¥ + ç›¸ä¼¼æ•™æé€çµ¦ GPT ç”Ÿæˆå›žç­”
    const gptResponse = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: "gpt-4o-mini",
        messages: [
          { role: "system", content: "ä½ æ˜¯ä¸€ä½åœ¨ MI æ•™å°Žé¼“ Technique çš„è€å¸«ï¼Œå¹«ä½¿ç”¨è€…æŠŠç·´ç¿’å…§å®¹æ•´ç†æˆé¼“å‹µèªžå¥" },
          { role: "user", content: `æ•™æåƒè€ƒ:\n${contextText}\nä½¿ç”¨è€…ç·´ç¿’å…§å®¹:\n${userText}` }
        ]
      })
    });

    const gptData = await gptResponse.json();
    const reply = gptData.choices[0].message.content;

    console.log("GPT å›žè¦†ï¼š", reply);

    res.json({ reply });

  } catch (err) {
    console.error("å¾Œç«¯ç™¼ç”ŸéŒ¯èª¤ï¼š", err);
    res.status(500).json({ error: "ä¼ºæœå™¨æˆ– GPT/Pinecone API ç™¼ç”ŸéŒ¯èª¤" });
  }
    
});
*/


// Heroku port è¨­å®š
const PORT = process.env.PORT || 3000;
app.listen(PORT, () => console.log(`âœ… Server running on port ${PORT}`));

// ç°¡å–® ping æ¸¬è©¦
app.get("/ping", (req, res) => {
  res.send("pong");
});
