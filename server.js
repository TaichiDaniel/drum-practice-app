const express = require("express");
const path = require("path");
// const fetch = require("node-fetch"); // Node 18+ å¯ç”¨å…¨åŸŸ fetchï¼Œä¹Ÿå¯ç”¨ node-fetch
const { Pinecone, ServerlessSpec } = require("@pinecone-database/pinecone");
const { OpenAI } = require("openai");

const app = express();
app.use(express.json());
app.use(express.static(path.join(__dirname, "public"))); // æä¾›å‰ç«¯éœæ…‹æª”æ¡ˆ

// è®€å–ç’°å¢ƒè®Šæ•¸
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const PINECONE_API_KEY = process.env.PINECONE_API_KEY;
const PINECONE_ENV = process.env.PINECONE_ENV;
const PINECONE_INDEX_NAME = process.env.PINECONE_INDEX_NAME;

// åˆå§‹åŒ– Pinecone å®¢æˆ¶ç«¯
const pc = new Pinecone({
  apiKey: PINECONE_API_KEY,
  // controllerHostUrl: "https://controller.us-east-1-aws.pinecone.io" // ä¾ç…§ä½ çš„ env region æ”¹
});

// å–å¾— Pinecone Index å¯¦ä¾‹
const pineconeIndex = pc.Index(PINECONE_INDEX_NAME);

console.log("ðŸ” Pinecone index:", PINECONE_INDEX_NAME);
console.log("ðŸ” Pinecone env:", PINECONE_ENV);
console.log("ðŸ” Controller URL:", "https://controller.us-east-1.pinecone.io");

// åˆå§‹åŒ– OpenAI
const openai = new OpenAI({ apiKey: OPENAI_API_KEY });

// POST /gpt è·¯ç”±ï¼šæŽ¥æ”¶å‰ç«¯è¼¸å…¥æ–‡å­—ï¼ŒæŸ¥ Pineconeï¼Œå†é€çµ¦ GPT
app.post("/gpt", async (req, res) => {

  /* æ¸¬è©¦å‰ç«¯fetch("/gpt") æ˜¯å¦èƒ½æ­£å¸¸å‘¼å«å¾Œç«¯ï¼Œä»¥åŠå¾Œç«¯ route æ˜¯å¦èƒ½å›žå‚³ JSON
  console.log("æ¸¬è©¦æ”¶åˆ°è«‹æ±‚", req.body);
  res.json({ reply: "å¾Œç«¯æ¸¬è©¦æˆåŠŸï¼" });
  */

  const userText = req.body.text;
  console.log("æ”¶åˆ°ç·´ç¿’å…§å®¹ï¼š", userText);

// -----------------------------
// ðŸˆ¶ è‡ªå‹•åµæ¸¬ä¸­æ–‡ â†’ ç¿»è­¯æˆè‹±æ–‡
// -----------------------------
let processedText = userText;

if (/[\u4e00-\u9fa5]/.test(userText)) {  // åµæ¸¬æ˜¯å¦å«ä¸­æ–‡
  console.log("ðŸ” åµæ¸¬åˆ°ä¸­æ–‡ï¼Œæ­£åœ¨ç¿»è­¯æˆè‹±æ–‡ä»¥åˆ©å‘é‡æ¯”å°...");

  try {
    const translation = await openai.chat.completions.create({
      model: "gpt-5-mini",
      messages: [
        {
          role: "system",
          content: "You are a translator that accurately translates Chinese text to English for semantic search on drum education materials."
        },
        { role: "user", content: userText }
      ]
    });

    processedText = translation.choices[0].message.content.trim();
    console.log("âœ… ç¿»è­¯å®Œæˆï¼š", processedText);
  } catch (e) {
    console.error("âš ï¸ ç¿»è­¯å¤±æ•—ï¼Œæ”¹ç”¨åŽŸå§‹è¼¸å…¥ï¼š", e.message);
  }
}

  try {
  // -----------------------------
  // 1ï¸âƒ£ å…ˆå‘¼å« OpenAI Embeddings ç”Ÿæˆå‘é‡
  // -----------------------------
  const embeddingResponse = await openai.embeddings.create({
    model: "text-embedding-3-small",
    input: processedText
  });

  // âœ… ç›´æŽ¥å–å›ž JS objectï¼Œä¸è¦å† .json()
  const userVector = embeddingResponse.data[0].embedding;

  // -----------------------------
  // 2ï¸âƒ£ æŸ¥è©¢ Pinecone
  // -----------------------------
  const queryResponse = await pineconeIndex.query({
    vector: userVector,
    topK: 5, // å–æœ€ç›¸ä¼¼çš„å‰ä¸‰å€‹æ®µè½
    includeMetadata: true
  });

  console.log("Pinecone æŸ¥è©¢çµæžœï¼š", JSON.stringify(queryResponse, null, 2));

  // -----------------------------
  // 3ï¸âƒ£ æ•´ç†æŸ¥åˆ°çš„æ®µè½å…§å®¹
  // -----------------------------
  const matchedTexts = queryResponse.matches.map(m => m.metadata.text);
  const contextText = matchedTexts.join("\n---\n");
/*
  let prompt = "";
  if (matchedTexts.length > 0) {
    prompt =
    
      `ä»¥ä¸‹æ˜¯æ•™æå…§å®¹çš„éƒ¨åˆ†æ‘˜éŒ„ï¼š\n\n` +
      matchedTexts.join("\n\n---\n\n") +
      `\n\nè«‹åªæ ¹æ“šä¸Šé¢çš„æ•™æå›žç­”å•é¡Œã€‚` +
      `å¦‚æžœæ•™æä¸­æ²’æœ‰ç­”æ¡ˆï¼Œè«‹å›žç­”ã€Œæ•™æä¸­æ²’æœ‰ç›¸é—œè³‡è¨Šã€ã€‚\n\n` +
      `å•é¡Œï¼š${userText}\nå›žç­”ï¼š`;
    
      prompt =
      `ä»¥ä¸‹æ˜¯æ•™æå…§å®¹çš„éƒ¨åˆ†æ‘˜éŒ„ï¼š\n\n` +
      matchedTexts.join("\n\n---\n\n") +
      `\n\nè«‹ä»¥100%æ•™ææŸ¥åˆ°çš„å…§å®¹å›žç­”å•é¡Œã€‚` +
      `å•é¡Œï¼š${userText}\nå›žç­”ï¼š`;
  } else {
    prompt =
      `æ•™æä¸­æ²’æœ‰ç›¸é—œè³‡è¨Šã€‚\n\n` +
      `å•é¡Œï¼š${userText}\nå›žç­”ï¼š`;
  }
*/
    // -----------------------------
    // 4ï¸âƒ£ å‘¼å« GPT ç”¢ç”Ÿå›žè¦†
    // -----------------------------
    const completion = await openai.chat.completions.create({
      model: "gpt-5-mini",
      messages: [
        {
          role: "system",
          content: "ä½ æ˜¯ä¸€ä½åœ¨ Musician Institute æ•™å°Žçˆµå£«é¼“çš„è€å¸«ï¼Œç†Ÿæ‚‰Techniqueã€Readingå’ŒPerformanceæ•™æå…§å®¹ã€‚è«‹æ ¹æ“šæ•™æå…§å®¹å›žç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚ä¸éœ€è¦é¼“å‹µçš„è©±ã€‚"
        },
        {
          role: "user",
          content: 
            `ä»¥ä¸‹æ˜¯æ•™æå…§å®¹çš„éƒ¨åˆ†æ‘˜éŒ„ï¼š\n\n${contextText}\n\n` +
            `è«‹æ ¹æ“šæ•™æå›žç­”å•é¡Œã€‚è‹¥æ•™æä¸­æ²’æœ‰æåˆ°ï¼Œè«‹å›žç­”ã€Œæ•™æä¸­æ²’æœ‰ç›¸é—œè³‡è¨Šã€ã€‚\n\n` +
            `å­¸ç”Ÿçš„å•é¡Œï¼š${userText}`
          
        }
      ]
    });

    const gptReply = completion.choices[0].message.content;

    console.log("GPT å›žè¦†ï¼š", gptReply);

    // -----------------------------
    // 5ï¸âƒ£ å›žå‚³æœ€çµ‚çµæžœçµ¦å‰ç«¯
    // -----------------------------
    res.json({
      reply: gptReply
    });
  } catch (err) {
    console.error("ç™¼ç”ŸéŒ¯èª¤ï¼š", err);
    res.status(500).json({ reply: "âŒ ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦\n\n" + err.message });
  }
});

  /* 
  try {
    // 1ï¸âƒ£ å…ˆç”¨ OpenAI çš„ embedding ç”Ÿæˆå‘é‡
    const embeddingResponse = await fetch("https://api.openai.com/v1/embeddings", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: "text-embedding-3-small",
        input: userText
      })
    });

    const embeddingData = await embeddingResponse.json();
    const userEmbedding = embeddingData.data[0].embedding; // å–å‡ºå‘é‡
    console.log("ä½¿ç”¨è€…å‘é‡ç”Ÿæˆå®Œæˆ");

    // 2ï¸âƒ£ æŸ¥è©¢ Pinecone æ‰¾æœ€ç›¸ä¼¼çš„æ•™æ
    const queryResponse = await pineconeIndex.query({
      vector: userEmbedding,
      topK: 3, // å–å¾—æœ€ç›¸ä¼¼çš„ 3 ç­†
      includeMetadata: true
    });

    // æŠŠæ‰¾åˆ°çš„æ®µè½å…§å®¹çµ„æˆ GPT prompt
    let contextText = "";
    queryResponse.matches.forEach((match, idx) => {
      contextText += `æ®µè½ ${idx + 1}: ${match.metadata.text}\n`;
    });

    console.log("å¾ž Pinecone å–å‡ºçš„ç›¸ä¼¼æ•™æï¼š", contextText);

    // 3ï¸âƒ£ æŠŠä½¿ç”¨è€…è¼¸å…¥ + ç›¸ä¼¼æ•™æé€çµ¦ GPT ç”Ÿæˆå›žç­”
    const gptResponse = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: "gpt-4o-mini",
        messages: [
          { role: "system", content: "ä½ æ˜¯ä¸€ä½åœ¨ MI æ•™å°Žé¼“ Technique çš„è€å¸«ï¼Œå¹«ä½¿ç”¨è€…æŠŠç·´ç¿’å…§å®¹æ•´ç†æˆé¼“å‹µèªžå¥" },
          { role: "user", content: `æ•™æåƒè€ƒ:\n${contextText}\nä½¿ç”¨è€…ç·´ç¿’å…§å®¹:\n${userText}` }
        ]
      })
    });

    const gptData = await gptResponse.json();
    const reply = gptData.choices[0].message.content;

    console.log("GPT å›žè¦†ï¼š", reply);

    res.json({ reply });

  } catch (err) {
    console.error("å¾Œç«¯ç™¼ç”ŸéŒ¯èª¤ï¼š", err);
    res.status(500).json({ error: "ä¼ºæœå™¨æˆ– GPT/Pinecone API ç™¼ç”ŸéŒ¯èª¤" });
  }
    
});
*/


// Heroku port è¨­å®š
const PORT = process.env.PORT || 3000;
app.listen(PORT, () => console.log(`âœ… Server running on port ${PORT}`));

// ç°¡å–® ping æ¸¬è©¦
app.get("/ping", (req, res) => {
  res.send("pong");
});
